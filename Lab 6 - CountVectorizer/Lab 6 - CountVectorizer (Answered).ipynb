{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 7 - Lab CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import CountVectorizer from sklearn...  nltk, and matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create an instance of the CountVectorizer class. use a variable called vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use the following sample text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['NLP is about text processing', 'Text processing is necessary.', \n",
    "          'Text processing is necessary and important.', 'Text processing is easy.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the fit() function in order to learn a vocabulary from the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's inspect  how our vectorizer vectorized the text\n",
    "#### print out a list of words used, and their index in the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary and indices:\n",
      "{'nlp': 6, 'is': 4, 'about': 0, 'text': 8, 'processing': 7, 'necessary': 5, 'and': 1, 'important': 3, 'easy': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary and indices:\")\n",
    "print(vectorizer.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a vector by passing the text into the vectorizer to get back counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = vectorizer.transform(corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### display the full vector. <br> use vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vectorized form (word counts):\n",
      "[[1 0 0 0 1 0 1 1 1]\n",
      " [0 0 0 0 1 1 0 1 1]\n",
      " [0 1 0 1 1 1 0 1 1]\n",
      " [0 0 1 0 1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVectorized form (word counts):\")\n",
    "print(vector.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print the One Hot vector for the word: \"necessary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-hot vector for the word 'necessary' (index 5):\n",
      "[0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "word_index = vectorizer.vocabulary_.get(\"necessary\")\n",
    "print(f\"\\nOne-hot vector for the word 'necessary' (index {word_index}):\")\n",
    "print(vector.toarray()[:, word_index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get the feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature names (words):\n",
      "['about' 'and' 'easy' 'important' 'is' 'necessary' 'nlp' 'processing'\n",
      " 'text']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"\\nFeature names (words):\")\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print the Frequency Distribution of the same text (corpus) using nltk.FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"NLP is about text processing, Text processing is necessary., \n",
    "          Text processing is necessary and important., Text processing is easy.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency Distribution of the corpus:\n",
      "[('is', 4), ('text', 4), ('processing', 4), (',', 3), ('nlp', 1), ('about', 1), ('necessary.', 1), ('necessary', 1), ('and', 1), ('important.', 1), ('easy', 1), ('.', 1)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_corpus = \"\"\"NLP is about text processing, Text processing is necessary., \n",
    "          Text processing is necessary and important., Text processing is easy.\"\"\"\n",
    "\n",
    "words = nltk.word_tokenize(text_corpus.lower())\n",
    "\n",
    "fdist = FreqDist(words)\n",
    "\n",
    "print(\"\\nFrequency Distribution of the corpus:\")\n",
    "print(fdist.most_common())\n",
    "\n",
    "fdist.plot(30, cumulative=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Let's use the Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import pandas, os, numpy, train_test_split, CountVectorizer, accuracy_score, and MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import the three text files provided: yelp_labelled.txt, amazon_cells_labelled.txt, and imdb_labelled.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence    Wow... Loved this place.\n",
      "label                       positive\n",
      "source                          yelp\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filepath_dict = {'yelp':   'yelp_labelled.txt',\n",
    "                 'amazon': 'amazon_cells_labelled.txt',\n",
    "                 'imdb':   'imdb_labelled.txt'}\n",
    "\n",
    "df_list = []\n",
    "for source, filepath in filepath_dict.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
    "    df['source'] = source  # Add another column filled with the source name: yelp, imdb, or amazon\n",
    "    df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### display the first five records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First five records:\n",
      "                                            sentence     label source\n",
      "0                           Wow... Loved this place.  positive   yelp\n",
      "1                                 Crust is not good.  negative   yelp\n",
      "2          Not tasty and the texture was just nasty.  negative   yelp\n",
      "3  Stopped by during the late May bank holiday of...  positive   yelp\n",
      "4  The selection on the menu was great and so wer...  positive   yelp\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst five records:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### display the last 10 \"negative\" reviews (sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 10 negative reviews:\n",
      "Empty DataFrame\n",
      "Columns: [sentence]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLast 10 negative reviews:\")\n",
    "negative_reviews = df[df['label'] == 0].tail(10)\n",
    "print(negative_reviews[['sentence']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>If you act in such a film, you should be glad ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>This one wants to surf on the small wave of sp...</td>\n",
       "      <td>negative</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>If you haven't choked in your own vomit by the...</td>\n",
       "      <td>negative</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>Instead, we got a bore fest about a whiny, spo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>I never walked out of a movie faster.</td>\n",
       "      <td>negative</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>negative</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>negative</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>negative</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>negative</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence     label source\n",
       "720  If you act in such a film, you should be glad ...  negative   imdb\n",
       "721  This one wants to surf on the small wave of sp...  negative   imdb\n",
       "722  If you haven't choked in your own vomit by the...  negative   imdb\n",
       "725  Instead, we got a bore fest about a whiny, spo...  negative   imdb\n",
       "742            I never walked out of a movie faster.    negative   imdb\n",
       "743  I just got bored watching Jessice Lange take h...  negative   imdb\n",
       "744  Unfortunately, any virtue in this film's produ...  negative   imdb\n",
       "745                   In a word, it is embarrassing.    negative   imdb\n",
       "746                               Exceptionally bad!    negative   imdb\n",
       "747  All in all its an insult to one's intelligence...  negative   imdb"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Test and Train Data into these variables: make the test size = 25% and random state = 42\n",
    "### train_set, test_set, train_label, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, train_label, test_label = train_test_split(\n",
    "    df['sentence'], df['label'], test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print the number of records in the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the training set: 2061\n",
      "Number of records in the test set: 687\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of records in the training set: {len(train_set)}\")\n",
    "print(f\"Number of records in the test set: {len(test_set)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize text data. Use the variables: countvect, x_counts, x_train_df, x_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvect = CountVectorizer()\n",
    "x_counts = countvect.fit_transform(df['sentence'])\n",
    "\n",
    "# preparing for training set\n",
    "x_train_df = countvect.fit_transform(train_set)\n",
    "\n",
    "# preparing for test set\n",
    "x_test_df = countvect.transform(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print the shape of x_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train_df: (2061, 4336)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of x_train_df: {x_train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use the Naive Bayes classifier. Use a variable called \"clf\" and fit the data (x_train_df,train_set.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "clf.fit(x_train_df, train_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model and print the accuracy of the Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier: 0.8079\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(x_test_df)\n",
    "\n",
    "accuracy = accuracy_score(test_label, predictions)\n",
    "print(f\"Accuracy of Naive Bayes Classifier: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do you believe this is a low accuracy value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of 80.79% for a Naive Bayes classifier is generally considered solid in text classification tasks, such as sentiment analysis of user reviews. This level of accuracy indicates significant improvement over random classifiers, which typically achieve around 50%. However, factors like task complexity, class imbalance, and the model's assumptions should be considered when evaluating this performance. To improve accuracy further, techniques such as feature engineering, trying different models (like Logistic Regression or SVM), and enhancing text preprocessing can be effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a function classify_review with a parameter called text. assing countvect.transform([text]) to a variable called pred1, and return clf.predict(pred1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text):\n",
    "    # your code goes here\n",
    "    pred1 = countvect.transform([text])\n",
    "    # end of your code\n",
    "    return clf.predict(pred1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model calling the function classify_review using the following sentences: <br> \"The food was amazing !!\" and \"The food was awful !!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reviews = [\n",
    "    \"The food was amazing !!\",\n",
    "    \"The food was awful !!\"\n",
    "]\n",
    "\n",
    "for review in test_reviews:\n",
    "    result = classify_review(review)\n",
    "    print(f\"The sentiment of the review '{review}' is: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Let's use Keras\n",
    "\n",
    "### import all the libraries needed: keras, Sequential, Tokenizer, KerasClassifier, LogisticRegression, OneHotEncoder, pad_sequences, tensorflow, layers, LabelEncoder, os, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\william\\anaconda3\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\william\\anaconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\william\\anaconda3\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\william\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\william\\anaconda3\\lib\\site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\william\\anaconda3\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\william\\anaconda3\\lib\\site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\william\\anaconda3\\lib\\site-packages (from keras) (0.13.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\william\\anaconda3\\lib\\site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\william\\anaconda3\\lib\\site-packages (from keras) (23.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\william\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\william\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\william\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\william\\anaconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\william\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\william\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\william\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\william\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\william\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\william\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\william\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\william\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### display the first five records of \"df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence     label source\n",
      "0                           Wow... Loved this place.  positive   yelp\n",
      "1                                 Crust is not good.  negative   yelp\n",
      "2          Not tasty and the texture was just nasty.  negative   yelp\n",
      "3  Stopped by during the late May bank holiday of...  positive   yelp\n",
      "4  The selection on the menu was great and so wer...  positive   yelp\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename the columns: for the \"label\" change negative for 0 and possitive for 1 and rename the colunns v1: negative, v2: sentence <br> use inplace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].map({'negative': 0, 'positive': 1})\n",
    "df.rename(columns={'label': 'negative', 'sentence': 'v2'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### display the top five records again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  v2  negative source\n",
      "0                           Wow... Loved this place.         1   yelp\n",
      "1                                 Crust is not good.         0   yelp\n",
      "2          Not tasty and the texture was just nasty.         0   yelp\n",
      "3  Stopped by during the late May bank holiday of...         1   yelp\n",
      "4  The selection on the menu was great and so wer...         1   yelp\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import train_test_split from sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split the data using the variables: X_train, X_test, y_train, y_test <br> test size = 0.2 and random_state=42 <br> hint: train_test_split(df['sentence'], df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['v2'], df['negative'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create an instance of the CountVectorizer class, Call the fit(X_train) function in order to learn a vocabulary from one or more documents, and apply vectorizer.transform to X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "# Enter two more lines of code here:\n",
    "\n",
    "x_train_counts = vectorizer.transform(X_train)\n",
    "x_test_counts = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a variable called \"logreg\" and create an instance of the LogisticRegression. Then fit the data on (X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(x_train_counts, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a variable called y_pred and predict the value of X_test_cv usign logreg.predict <br> then print the accuracy of the logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Classifier: 0.8273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(x_test_counts)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of Logistic Regression Classifier: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What model gave you a hiher accuracy, logistic regression or the Naive Bayes classifier? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the models was compared based on the results obtained from their respective classifications. The Logistic Regression classifier achieved an accuracy of 0.8273, while the Naive Bayes classifier recorded a slightly lower accuracy of 0.8079. This indicates that the Logistic Regression model performed better than the Naive Bayes classifier on the dataset used for the classification task. Overall, the findings suggest that Logistic Regression is a more effective model for this particular scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                             Wow... Loved this place.\n",
      "0    A very, very, very slow-moving, aimless movie ...\n",
      "Name: sentence, dtype: object\n",
      "[124, 314, 289, 2, 755, 916, 8, 101, 290, 15, 6]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=3000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_emb = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_emb = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "print(X_train[0])\n",
    "print(X_train_emb[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the messages should have the same lenght. \n",
    "\n",
    "### Use pad_sequences to make the maxlen of all the messages = 100 and apply this to the X_train and X_test values. <br> Then print (X_train[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 124\n",
      " 314 289   2 755 916   8 101 290  15   6]\n"
     ]
    }
   ],
   "source": [
    "maxlen = 100\n",
    "### your code goes here:\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=3000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "\n",
    "X_train_emb = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_emb = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "maxlen = 100  \n",
    "X_train_padded = pad_sequences(X_train_emb, maxlen=maxlen)\n",
    "X_test_padded = pad_sequences(X_test_emb, maxlen=maxlen)\n",
    "\n",
    "\n",
    "print(X_train_padded[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Neural Network model\n",
    "\n",
    "The layers are stacked sequentially to build the classifier:\n",
    "\n",
    "create the model = keras.Sequential()\n",
    "\n",
    "The first layer is an Embedding layer. make it embedding_dim = 50.  This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding).\n",
    "\n",
    "Next, a GlobalAveragePooling1D layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\n",
    "This fixed-length output vector is piped through a fully-connected (Dense) layer with 16 neurons and activation function relu\n",
    "\n",
    "\n",
    "The last layer is densely connected with a single output node. Using the sigmoid activation function, this value is a float between 0 and 1, representing a probability, or confidence level. \n",
    "\n",
    "compile the model using: optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "\n",
    "# Assuming you have your training and test data (X_train, X_test) defined\n",
    "tokenizer = Tokenizer(num_words=3000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert texts to sequences\n",
    "X_train_emb = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_emb = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Define vocab_size\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 for the reserved 0 index\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the Embedding layer (removed input_length)\n",
    "embedding_dim = 50\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "\n",
    "# Add GlobalAveragePooling1D layer\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "# Add hidden layer with 16 neurons and activation function 'relu'\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Add output layer with one neuron and activation 'sigmoid'\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print the summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit the model using: X_train, y_train, epochs=30, verbose = 1, validation_data=(X_test, y_test), batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4756 - loss: 0.6938 - val_accuracy: 0.4818 - val_loss: 0.6939\n",
      "Epoch 2/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5039 - loss: 0.6932 - val_accuracy: 0.4818 - val_loss: 0.6942\n",
      "Epoch 3/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5204 - loss: 0.6919 - val_accuracy: 0.4818 - val_loss: 0.6935\n",
      "Epoch 4/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4876 - loss: 0.6929 - val_accuracy: 0.4873 - val_loss: 0.6916\n",
      "Epoch 5/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5431 - loss: 0.6901 - val_accuracy: 0.4818 - val_loss: 0.6912\n",
      "Epoch 6/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5633 - loss: 0.6878 - val_accuracy: 0.5255 - val_loss: 0.6868\n",
      "Epoch 7/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5736 - loss: 0.6822 - val_accuracy: 0.4818 - val_loss: 0.7011\n",
      "Epoch 8/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5677 - loss: 0.6684 - val_accuracy: 0.6164 - val_loss: 0.6672\n",
      "Epoch 9/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6127 - loss: 0.6633 - val_accuracy: 0.5473 - val_loss: 0.6625\n",
      "Epoch 10/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7238 - loss: 0.6257 - val_accuracy: 0.6945 - val_loss: 0.6303\n",
      "Epoch 11/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7418 - loss: 0.5893 - val_accuracy: 0.6873 - val_loss: 0.6041\n",
      "Epoch 12/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7988 - loss: 0.5454 - val_accuracy: 0.7455 - val_loss: 0.5639\n",
      "Epoch 13/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7633 - loss: 0.5153 - val_accuracy: 0.7345 - val_loss: 0.5557\n",
      "Epoch 14/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8401 - loss: 0.4566 - val_accuracy: 0.7764 - val_loss: 0.5120\n",
      "Epoch 15/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8541 - loss: 0.4092 - val_accuracy: 0.7418 - val_loss: 0.4991\n",
      "Epoch 16/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7979 - loss: 0.4162 - val_accuracy: 0.7764 - val_loss: 0.4857\n",
      "Epoch 17/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8836 - loss: 0.3472 - val_accuracy: 0.7600 - val_loss: 0.4960\n",
      "Epoch 18/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8373 - loss: 0.3619 - val_accuracy: 0.7836 - val_loss: 0.4574\n",
      "Epoch 19/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8691 - loss: 0.3185 - val_accuracy: 0.6964 - val_loss: 0.5610\n",
      "Epoch 20/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8622 - loss: 0.3315 - val_accuracy: 0.7855 - val_loss: 0.4444\n",
      "Epoch 21/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9086 - loss: 0.2650 - val_accuracy: 0.7582 - val_loss: 0.4601\n",
      "Epoch 22/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8961 - loss: 0.2771 - val_accuracy: 0.7982 - val_loss: 0.4364\n",
      "Epoch 23/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9302 - loss: 0.2434 - val_accuracy: 0.8091 - val_loss: 0.4217\n",
      "Epoch 24/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8784 - loss: 0.2910 - val_accuracy: 0.8091 - val_loss: 0.4189\n",
      "Epoch 25/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.2197 - val_accuracy: 0.7800 - val_loss: 0.4429\n",
      "Epoch 26/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.2159 - val_accuracy: 0.8200 - val_loss: 0.4304\n",
      "Epoch 27/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9380 - loss: 0.1859 - val_accuracy: 0.7964 - val_loss: 0.4329\n",
      "Epoch 28/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2018 - val_accuracy: 0.8200 - val_loss: 0.4283\n",
      "Epoch 29/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.1877 - val_accuracy: 0.8218 - val_loss: 0.4288\n",
      "Epoch 30/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9334 - loss: 0.1817 - val_accuracy: 0.7564 - val_loss: 0.4837\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_padded, y_train, \n",
    "                    epochs=30, \n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test_padded, y_test), \n",
    "                    batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate the model and print the training and testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7653 - loss: 0.4632\n",
      "Training Accuracy: 0.9440\n",
      "Testing Accuracy: 0.7564\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_padded, y_test, verbose=1)\n",
    "\n",
    "print(f\"Training Accuracy: {history.history['accuracy'][-1]:.4f}\")  # Last epoch training accuracy\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
